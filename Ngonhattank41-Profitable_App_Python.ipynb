{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f2cee5",
   "metadata": {},
   "source": [
    "# Profitable apps for the app store and Google Play\n",
    "\n",
    "## This project is about:\n",
    "we'll pretend we're working as data analysts for a company that builds Android and iOS mobile apps. We make our apps available on Google Play and the App Store.\n",
    "\n",
    "We only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means our revenue for any given app is mostly influenced by the number of users who use our app ‚Äî the more users that see and engage with the ads, the better.\n",
    "### The goal of this project is: \n",
    "To analyze data to help our developers understand what type of apps are likely to attract more users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed53fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e53edb",
   "metadata": {},
   "source": [
    "# Opening the data files and storing them as list datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67734ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 2693: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ee13986c0f99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcsv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mread_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mios_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mopened_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'googleplaystore.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mread_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 2693: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "opened_file = open('Applestore.csv')\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "ios_data = list(read_file)\n",
    "opened_file = open('googleplaystore.csv')\n",
    "read_file = reader(opened_file)\n",
    "android_data = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825eab0c",
   "metadata": {},
   "source": [
    "# deleting the row with incorrect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(android_data[10473])\n",
    "print(android_data[10474])\n",
    "print(len(android_data))\n",
    "##del android_data[10473]\n",
    "print(android_data[10473])\n",
    "print(len(android_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9126b107",
   "metadata": {},
   "source": [
    "# Removing Duplicate Entries\n",
    "## Part One\n",
    "If we explore the Google Play data set long enough, we'll find that some apps have more than one entry. For instance, the application Instagram has four entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bffd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "##find duplicate entries\n",
    "def find_duplicates(dataset):\n",
    "    duplicate_apps = []\n",
    "    unique_apps = []\n",
    "    for row in dataset[1:]:\n",
    "        if row[0] in unique_apps:\n",
    "            duplicate_apps.append(row[0])\n",
    "        else:\n",
    "            unique_apps.append(row[0])\n",
    "    return duplicate_apps, unique_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc61d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_apps, uni_apps = find_duplicates(android_data)\n",
    "print(len(uni_apps))\n",
    "print(len(dup_apps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b3c73",
   "metadata": {},
   "source": [
    "We don't want to count certain apps more than once when we analyze data, so we need to remove the duplicate entries and keep only one entry per app. One thing we could do is remove the duplicate rows randomly, but we could probably find a better way.\n",
    "\n",
    "The main difference happens on the fourth position of each row, which corresponds to the number of reviews. The different numbers show that the data was collected at different times. We can use this to build a criterion for keeping rows. We won't remove rows randomly, but rather we'll keep the rows that have the highest number of reviews because the higher the number of reviews, the more reliable the ratings.\n",
    "\n",
    "To do that, we will:\n",
    "\n",
    "Create a dictionary where each key is a unique app name, and the value is the highest number of reviews of that app\n",
    "Use the dictionary to create a new data set, which will have only one entry per app (and we only select the apps with the highest number of reviews)\n",
    "# Part Two\n",
    "Let's start by building the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef409513",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "for row in android_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if name in reviews_max and reviews_max[name] <= n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0c46b",
   "metadata": {},
   "source": [
    "Now using the dictionary created above, delete the duplicate entries in the android data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31a3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = [] #android_data[0]\n",
    "already_added = []\n",
    "for row in android_data[1:]:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if name in reviews_max and reviews_max[name] == n_reviews and name not in already_added:\n",
    "        android_clean.append(row)\n",
    "        already_added.append(name)\n",
    "        #del android_data[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b142902",
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(android_clean, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5088f331",
   "metadata": {},
   "source": [
    " # A function to find non english characters in the app name\n",
    " ## Part one\n",
    " \n",
    " Write a function that takes in a string and returns *False* if there's any character in the string that doesn't belong to the set of common English characters, otherwise it returns *True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ascii(app_name):\n",
    "    for character in app_name:\n",
    "        if ord(character) > 127:\n",
    "            return character, False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647def69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_ascii('Instagram'))\n",
    "print(find_ascii('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print(find_ascii('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "print(find_ascii('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90293cc6",
   "metadata": {},
   "source": [
    "# Part Two\n",
    "To minimize the impact of data loss, we'll only remove an app if its name has more than three non-ASCII characters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english(app_name):\n",
    "    counter = 0\n",
    "    for character in app_name:\n",
    "        if ord(character) > 127:\n",
    "            counter += 1\n",
    "    if counter > 3:\n",
    "            return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(is_english('Instagram'))\n",
    "print(is_english('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "print(is_english('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "print(is_english('Instachat üòú'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef79f7",
   "metadata": {},
   "source": [
    "Now we have to use the is_english function to create android and ios english apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a23d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "android_english = [] #android_data[0]\n",
    "ios_english = []\n",
    "for row in android_clean:\n",
    "    name = row[0]\n",
    "    if is_english(name):\n",
    "        android_english.append(row)\n",
    "for row in ios_data[1:]:\n",
    "    name = row[1]#name is second column\n",
    "    if is_english(name):\n",
    "        ios_english.append(row)\n",
    "\n",
    "explore_data(android_english, 0, 3, True)\n",
    "print('\\n')\n",
    "explore_data(ios_english, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36801f9",
   "metadata": {},
   "source": [
    "We can see that we're left with 9614 Android apps and 6183 iOS apps.\n",
    "# Isolating the Free Apps\n",
    "As we mentioned in the introduction, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. Our data sets contain both free and non-free apps, and we'll need to isolate only the free apps for our analysis. Below, we isolate the free apps for both our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8726dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "android_final = []\n",
    "ios_final = []\n",
    "\n",
    "for row in android_english:\n",
    "    #app_type = row[6]\n",
    "    #if app_type == 'Free':\n",
    "    price = row[7]\n",
    "    if price == '0':\n",
    "        android_final.append(row)\n",
    "    #elif app_type != 'Paid':\n",
    "    #    print(row)\n",
    "for row in ios_english:\n",
    "    price = row[4]\n",
    "    if price == '0.0':\n",
    "        ios_final.append(row)\n",
    "        \n",
    "explore_data(android_final, 0, 4, True)\n",
    "explore_data(ios_final, 0, 4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520667a8",
   "metadata": {},
   "source": [
    "We're left with 8864 Android apps and 3222 iOS apps, which should be enough for our analysis.\n",
    "# Most Common Apps by Genre\n",
    "## Part One\n",
    "As we mentioned in the introduction, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, we then develop it further.\n",
    "3. If the app is profitable after six months, we also build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "Because our end goal is to add the app on both the App Store and Google Play, we need to find app profiles that are successful on both markets. For instance, a profile that might work well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "Let's begin the analysis by getting a sense of the most common genres for each market. For this, we'll build a frequency table for the prime_genre column of the App Store data set, and the Genres and Category columns of the Google Play data set.\n",
    "## Part Two\n",
    "We'll build two functions we can use to analyze the frequency tables:\n",
    "1. One function to generate frequency tables that show percentages\n",
    "2. Another function that we can use to display the percentages in a descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    fre_table = {}\n",
    "    total_apps = 0\n",
    "    for row in dataset:\n",
    "        value = row[index]\n",
    "        total_apps += 1\n",
    "        if value in fre_table:\n",
    "            fre_table[value] += 1      \n",
    "        else:\n",
    "            fre_table[value] = 1\n",
    "    #find percentage\n",
    "    app_percentage = {}\n",
    "    for key in fre_table:\n",
    "        app_percentage[key] = (fre_table[key]/total_apps) * 100\n",
    "    \n",
    "    return app_percentage\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_value_as_tuple = (table[key], key)\n",
    "        table_display.append(key_value_as_tuple)\n",
    "    #now sort\n",
    "    final_table = sorted(table_display, reverse = True)\n",
    "    \n",
    "    for entry in final_table:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e11f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_final,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_final, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(ios_final, -5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36508cb",
   "metadata": {},
   "source": [
    "# Most popular apps by genre\n",
    "\n",
    "One way to find out what genres are the most popular (have the most users) is to calculate the average number of installs for each app genre. For the Google Play data set, we can find this information in the Installs column, but for the App Store data set this information is missing. As a workaround, we'll take the total number of user ratings as a proxy, which we can find in the rating_count_tot app.\n",
    "\n",
    "Below, we calculate the average number of user ratings per app genre on the App Store:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_ios = freq_table(ios_final, -5)\n",
    "\n",
    "for genre in genre_ios:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    for row in ios_final:\n",
    "        genre_app = row[-5]\n",
    "        if genre == genre_app:\n",
    "            total = total + float(row[5])\n",
    "            len_genre += 1\n",
    "    #total ratings by genre\n",
    "    genre_tot = total/len_genre\n",
    "    genre_ios[genre] = genre_tot\n",
    "    print(genre, ':', genre_tot)\n",
    "print(genre_ios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a2c1b",
   "metadata": {},
   "source": [
    "Now let's analyze the Google Play market a bit.\n",
    "# Most Popular Apps by Genre on Google Play\n",
    "For the Google Play market, we actually have data about the number of installs, so we should be able to get a clearer picture about genre popularity. However, the install numbers don't seem precise enough ‚Äî we can see that most values are open-ended (100+, 1,000+, 5,000+, etc.):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(android_final, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0b975",
   "metadata": {},
   "source": [
    "One problem with this data is that is not precise. For instance, we don't know whether an app with 100,000+ installs has 100,000 installs, 200,000, or 350,000. However, we don't need very precise data for our purposes ‚Äî we only want to get an idea which app genres attract the most users, and we don't need perfect precision with respect to the number of users.\n",
    "\n",
    "We're going to leave the numbers as they are, which means that we'll consider that an app with 100,000+ installs has 100,000 installs, and an app with 1,000,000+ installs has 1,000,000 installs, and so on.\n",
    "To perform computations, however, we'll need to convert each install number to float ‚Äî this means that we need to remove the commas and the plus characters, otherwise the conversion will fail and raise an error. We'll do this directly in the loop below, where we also compute the average number of installs for each genre (category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using high level categories column for android apps instead of genre column\n",
    "\n",
    "category_android = freq_table(android_final, 1)\n",
    "\n",
    "for category in category_android:\n",
    "    total = 0\n",
    "    len_category = 0\n",
    "    for row in android_final:\n",
    "        category_app = row[1]\n",
    "        if category == category_app:\n",
    "            install_ct = row[5]\n",
    "            install_ct = install_ct.replace('+','')\n",
    "            install_ct = install_ct.replace(',','')\n",
    "            total += float(install_ct)\n",
    "            len_category += 1\n",
    "    #total ratings by category\n",
    "    category_tot = total/len_category\n",
    "    category_android[category] = category_tot\n",
    "    print(category, ':', category_tot)\n",
    "print(category_android)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ea59f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "294b99f01b6a31520fa3c448e068729ec0952542c5a230dffea968c158f72309"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
